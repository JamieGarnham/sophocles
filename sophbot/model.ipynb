{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sophocles' 'Oedipus Tyrannus' Line 625a Conjecture Analyser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install nltk for bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric #1: Vocabulary (forms)\n",
    "#### Count frequency of all forms in Sophocles' works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sophraw.txt\", \"r\", encoding='utf8') as inputfile:\n",
    "    text = inputfile.read()\n",
    "\n",
    "with open(\"sophraw.txt\", \"r\", encoding='utf8') as inputfile:\n",
    "    lines = inputfile.readlines()\n",
    "\n",
    "words = text.split()\n",
    "stripped_words = []\n",
    "for word in words:\n",
    "    stripped_word = word.strip(',;.ʼ·:!')\n",
    "    stripped_words.append(stripped_word)\n",
    "word_dict = {}\n",
    "for word in stripped_words:\n",
    "    if word not in word_dict:\n",
    "        word_dict[word] = 1\n",
    "    else:\n",
    "        word_dict[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determine maximum-scoring and minimum-scoring lines (for normalisation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_scores = {}\n",
    "for line in lines:\n",
    "    vocab_scores[line] = 0\n",
    "    words = line.split()\n",
    "    num = len(words)\n",
    "    for word in words:\n",
    "        new_word = word.strip(',;.ʼ·:!')\n",
    "        vocab_scores[line] += round(word_dict[new_word] / num, 2)\n",
    "\n",
    "# Most 'Sophoclean' (hexametric) line (by vocab, scaled): Antigone 667: \"καὶ σμικρὰ καὶ δίκαια καὶ τἀναντία.\" - (spoken by Creon) score of 513\n",
    "vocab_max = 513\n",
    "\n",
    "# Least 'Sophoclean'(hexametric) line (by vocab, scaled): Ajax 820: \"σιδηροβρῶτι θηγάνῃ νεηκονής·.\" (spoken by Ajax) - score of 1 (among others)\n",
    "vocab_min = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric #2: Vocabulary (lemmas)\n",
    "#### Count frequency of lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sophlemmas.txt\", \"r\", encoding='utf8') as lemmafile:\n",
    "    lemmas_raw = lemmafile.read()\n",
    "\n",
    "lemmas = lemmas_raw.split()\n",
    "lemma_dict = {}\n",
    "prev = \"\"\n",
    "for lemma in lemmas:\n",
    "    cur = lemma\n",
    "    if cur not in lemma_dict:\n",
    "        lemma_dict[cur] = 1\n",
    "    else:\n",
    "        if cur != prev:\n",
    "            lemma_dict[cur] += 1\n",
    "    prev = cur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Due to the need to manually lemmatise each line, determining the exact maximum-scoring and minimum-scoring lines was infeasible for this metric. Instead, a hypothetical normalisation of factor of 200 (based on the logic that a line containing only the most common non-stopwords would score just over 200, and a line containing only unique words would score 3 or 4, leading to a difference between maximum and minimum of approximately 200) was used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_norm = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric #3: Syntax/style (bigrams)\n",
    "#### Count frequency of bigrams in Sophocles' works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_bigrams = []\n",
    "bigrams_lines = []\n",
    "for line in lines:\n",
    "    words = line.split()\n",
    "    stripped_words = []\n",
    "    for word in words:\n",
    "        stripped_word = word.strip(',;.ʼ·:!')\n",
    "        stripped_words.append(stripped_word)\n",
    "    stripped_words.insert(0, 'start')\n",
    "    stripped_words.append('end')\n",
    "    bigrams = list(nltk.bigrams(stripped_words))\n",
    "    all_bigrams = all_bigrams + bigrams\n",
    "    bigrams_lines.append(bigrams)\n",
    "    \n",
    "bigram_dict = {}\n",
    "for bigram in all_bigrams:\n",
    "    if bigram not in bigram_dict:\n",
    "        bigram_dict[bigram] = 1\n",
    "    else:\n",
    "        bigram_dict[bigram] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determine maximum-scoring and minimum-scoring lines (for normalisation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_scores = {}\n",
    "for line in bigrams_lines:\n",
    "    bigram_scores[tuple(line)] = 0\n",
    "    for bigram in line:\n",
    "        bigram_scores[tuple(line)] += bigram_dict[bigram]\n",
    "\n",
    "# Most 'Sophoclean' (hexametric) line (by syntax/style): Philoctetes 1020: \"ἀλλʼ οὐ γὰρ οὐδὲν θεοὶ νέμουσιν ἡδύ μοι,\" (spoken by Philoctetes) - score of 551\n",
    "bigram_max = 551\n",
    "\n",
    "# Least 'Sophoclean'(hexametric) line (by syntax/style): Ajax 820: \"σιδηροβρῶτι θηγάνῃ νεηκονής·.\" (spoken by Ajax) - score of 4 (among others)\n",
    "bigram_min = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric #4: Amount of information (stop words, support words, and significant words)\n",
    "#### Use list of stop words from Perseus and remove diacritics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_raw = ['μή', 'ἑαυτοῦ', 'ἄν', 'ἀλλʼ', 'ἀλλά', 'ἄλλος', 'ἀπό', 'ἄρα',\n",
    "             'αὐτός', 'δʼ', 'δέ', 'δή', 'διά', 'δαί', 'δαίς', 'ἔτι', 'ἐγώ',\n",
    "             'ἐκ', 'ἐμός', 'ἐν', 'ἐπί', 'εἰ', 'εἰμί', 'εἴμι', 'εἰς', 'γάρ', 'γε', 'γʼ',\n",
    "             'γα', 'ἡ', 'ἤ', 'καί', 'κατά', 'μʼ', 'μέν', 'μετά', 'μή', 'ὁ', 'ὅδε',\n",
    "             'ὅς', 'ὅστις', 'ὅτι', 'οὕτως', 'οὗτος', 'οὔτε', 'οὖν', 'οὐδείς',\n",
    "             'οἱ', 'οὐ', 'οὐδέ', 'οὐκ', 'περί', 'πρός', 'σύ', 'σʼ', 'σύν', 'τά', 'τʼ', 'τε',\n",
    "             'τήν', 'τῆς', 'τῇ', 'τι', 'τί', 'τις', 'τίς', 'τό', 'τοί',\n",
    "             'τοιοῦτος', 'τόν', 'τούς', 'τοῦ', 'τῶν', 'τῷ', 'ὑμός', 'ὑπέρ',\n",
    "             'ὑπό', 'ὡς', 'ὦ', 'ὥστε', 'ἐάν', 'παρά', 'σός']\n",
    "\n",
    "stopwords = []\n",
    "for stopword in stopwords_raw:\n",
    "    stopword = stopword.strip(\"',;.ʼ·:!\")\n",
    "    bare_word = \"\"\n",
    "    for letter in stopword:\n",
    "        if letter in 'ἈἉἊἋἌἍἎἏᾺἀἁἂἃἄἅἆἇὰᾶάᾼᾈᾉᾊᾋᾌᾍᾎᾏᾳᾀᾁᾂᾃᾄᾅᾆᾇᾲᾷ':\n",
    "            bare_word = bare_word + 'α'\n",
    "        elif letter in 'ἘἙἚἛἜἝῈἐἑἒἓἔἕὲέ':\n",
    "            bare_word = bare_word + 'ε'\n",
    "        elif letter in 'ἨἩἪἫἬἭἮἯῊἠἡἢἣἤἥἦἧὴῆήῌᾘᾙᾚᾛᾝᾞᾟῃᾐᾑᾒᾓᾔᾕᾖᾗῂῇῄ':\n",
    "            bare_word = bare_word + 'η'\n",
    "        elif letter in 'ἸἹἺἻἼἽἾἿῚἰἱἲἳἴἵἶἷὶῖί':\n",
    "            bare_word = bare_word + 'ι'\n",
    "        elif letter in 'ὈὉὊὋὌὍῸὀὁὂὃὄὅὸό':\n",
    "           bare_word = bare_word + 'ο'\n",
    "        elif letter in 'ὙὛὝὟῪὐὑὒὓὔὕὖὗὺῦῧῢΰύ':\n",
    "           bare_word = bare_word + 'υ'\n",
    "        elif letter in 'ὨὩὪὫὬὭὮὯῺὠὡὢὣὤὥὦὧὼῶώῼᾨᾩᾪᾫᾬᾭᾮᾯῳᾠᾡᾢᾣᾤᾥᾦᾧῲῷῴ':\n",
    "           bare_word = bare_word + 'ω'\n",
    "        else:\n",
    "          bare_word = bare_word + letter\n",
    "    stopwords.append(bare_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use list of support words from Github user and remove diacritics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"stopwords-el.txt\", \"r\", encoding='utf8') as midwordfile:\n",
    "    midwords_raw = midwordfile.readlines()         \n",
    "\n",
    "midwords = []\n",
    "for midword in midwords_raw:\n",
    "    midword = midword.strip()\n",
    "    midword = midword.strip(\"',;.ʼ·:!\")\n",
    "    bare_word = \"\"\n",
    "    for letter in midword:\n",
    "        if letter in 'ἈἉἊἋἌἍἎἏᾺἀἁἂἃἄἅἆἇὰᾶάᾼᾈᾉᾊᾋᾌᾍᾎᾏᾳᾀᾁᾂᾃᾄᾅᾆᾇᾲᾷ':\n",
    "            bare_word = bare_word + 'α'\n",
    "        elif letter in 'ἘἙἚἛἜἝῈἐἑἒἓἔἕὲέ':\n",
    "            bare_word = bare_word + 'ε'\n",
    "        elif letter in 'ἨἩἪἫἬἭἮἯῊἠἡἢἣἤἥἦἧὴῆήῌᾘᾙᾚᾛᾝᾞᾟῃᾐᾑᾒᾓᾔᾕᾖᾗῂῇῄ':\n",
    "            bare_word = bare_word + 'η'\n",
    "        elif letter in 'ἸἹἺἻἼἽἾἿῚἰἱἲἳἴἵἶἷὶῖί':\n",
    "            bare_word = bare_word + 'ι'\n",
    "        elif letter in 'ὈὉὊὋὌὍῸὀὁὂὃὄὅὸό':\n",
    "           bare_word = bare_word + 'ο'\n",
    "        elif letter in 'ὙὛὝὟῪὐὑὒὓὔὕὖὗὺῦῧῢΰύ':\n",
    "           bare_word = bare_word + 'υ'\n",
    "        elif letter in 'ὨὩὪὫὬὭὮὯῺὠὡὢὣὤὥὦὧὼῶώῼᾨᾩᾪᾫᾬᾭᾮᾯῳᾠᾡᾢᾣᾤᾥᾦᾧῲῷῴ':\n",
    "           bare_word = bare_word + 'ω'\n",
    "        else:\n",
    "          bare_word = bare_word + letter\n",
    "    midwords.append(bare_word)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove diacritics from the text, and determine maximum-scoring and minimum-scoring lines (for normalisation) by scoring stop words as 1, support words as 2, and other words as 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_max = 0\n",
    "cur_min = 99\n",
    "max_line = \"\"\n",
    "min_line = \"\"\n",
    "for line in lines:\n",
    "    line_score = 0\n",
    "    words = line.split()\n",
    "    bare_words = []\n",
    "    for word in words:\n",
    "        bare_word = \"\"\n",
    "        stripped_word = word.strip(',;.ʼ·:!')\n",
    "        for letter in stripped_word:\n",
    "            if letter in 'ἈἉἊἋἌἍἎἏᾺἀἁἂἃἄἅἆἇὰᾶάᾼᾈᾉᾊᾋᾌᾍᾎᾏᾳᾀᾁᾂᾃᾄᾅᾆᾇᾲᾷ':\n",
    "                bare_word = bare_word + 'α'\n",
    "            elif letter in 'ἘἙἚἛἜἝῈἐἑἒἓἔἕὲέ':\n",
    "                bare_word = bare_word + 'ε'\n",
    "            elif letter in 'ἨἩἪἫἬἭἮἯῊἠἡἢἣἤἥἦἧὴῆήῌᾘᾙᾚᾛᾝᾞᾟῃᾐᾑᾒᾓᾔᾕᾖᾗῂῇῄ':\n",
    "                bare_word = bare_word + 'η'\n",
    "            elif letter in 'ἸἹἺἻἼἽἾἿῚἰἱἲἳἴἵἶἷὶῖί':\n",
    "                bare_word = bare_word + 'ι'\n",
    "            elif letter in 'ὈὉὊὋὌὍῸὀὁὂὃὄὅὸό':\n",
    "                bare_word = bare_word + 'ο'\n",
    "            elif letter in 'ὙὛὝὟῪὐὑὒὓὔὕὖὗὺῦῧῢΰύ':\n",
    "                bare_word = bare_word + 'υ'\n",
    "            elif letter in 'ὨὩὪὫὬὭὮὯῺὠὡὢὣὤὥὦὧὼῶώῼᾨᾩᾪᾫᾬᾭᾮᾯῳᾠᾡᾢᾣᾤᾥᾦᾧῲῷῴ':\n",
    "                bare_word = bare_word + 'ω'\n",
    "            else:\n",
    "                bare_word = bare_word + letter\n",
    "        bare_words.append(bare_word)\n",
    "\n",
    "    for bare_word in bare_words:\n",
    "        if bare_word in stopwords:\n",
    "            line_score += 1\n",
    "        elif bare_word in midwords:\n",
    "            line_score += 2\n",
    "        else:\n",
    "            line_score += 3\n",
    "    if line_score > cur_max:\n",
    "        cur_max = line_score\n",
    "        max_line = line\n",
    "\n",
    "    if line_score < cur_min:\n",
    "        cur_min = line_score\n",
    "        min_line = line\n",
    "\n",
    "\n",
    "# Most 'significant' (hexametric) line: Philoctetes 989: \"Ζεύς ἐσθʼ, ἵνʼ εἰδῇς, Ζεύς, ὁ τῆσδε γῆς κρατῶν,\" (spoken by Odysseus) - score of 24\n",
    "signif_max = 24\n",
    "\n",
    "# Least 'significant' (hexametric) line: Oedipus at Colonus 1269: \"παρασταθήτω· τῶν γὰρ ἡμαρτημένων\" (spoken by Polynices) - score of 8\n",
    "signif_min = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine normalised scores for each conjecture\n",
    "\n",
    "#### Metric #1: Vocabulary (forms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric #1: Vocab (forms) scores\n",
      "ὅς γ’ οὐ λογίζῃ, πῶς δε πιστεύοιμι σοι; 0.1582\n",
      "ὥς στέρεος εῖ! τί οὐχὶ πιστεύεις ἐμοί; 0.1309\n",
      "θέλεις λέγειν με δεῖν πιθέσθαι σοι, Κρέων; 0.1099\n",
      "τί ποτε πιθοίμην ἂν γε τοῖςδε σοῖς λόγοις; 0.2432\n",
      "μηδείς δε πιστεύσει γέ σοι, ὀρθῶς φρονῶν. 0.048\n"
     ]
    }
   ],
   "source": [
    "with open(\"conjectures.txt\", \"r\", encoding='utf8') as conjfile:\n",
    "    conjectures = conjfile.readlines()\n",
    "\n",
    "print(\"Metric #1: Vocab (forms) scores\")\n",
    "conj_vocab_scores = {}\n",
    "for conjecture in conjectures:\n",
    "    conj_vocab_scores[conjecture] = 0\n",
    "    words = conjecture.split()\n",
    "    num = len(words)\n",
    "    for word in words:\n",
    "        new_word = word.strip(',;.ʼ·:!')\n",
    "        if new_word in word_dict:\n",
    "            conj_vocab_scores[conjecture] += word_dict[new_word] / num\n",
    "    conj_vocab_scores[conjecture] = round((conj_vocab_scores[conjecture] - vocab_min) / (vocab_max - vocab_min), 4)\n",
    "    print(conjecture.strip(), conj_vocab_scores[conjecture])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric #2: Vocabulary (lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric #2: Vocab (lemmas) scores\n",
      "ὅς γε οὐ λογίζομαι πῶς δέ πιστεύω σύ 0.10166666666666667\n",
      "ὡς στερεός εἰ τίς οὐ πιστεύω ἐμός ἐγώ 0.02\n",
      "ἐθέλω λέγω ἐγώ δεῖ πείθω σύ Κρέων 0.431\n",
      "τίς ποτέ πείθω ἄν γε ὅδε σός λόγος 0.62875\n",
      "μηδείς δέ πιστεύω γε σύ ὀρθός φρονέω 0.16125\n"
     ]
    }
   ],
   "source": [
    "with open(\"conjlemmas.txt\", \"r\", encoding='utf8') as conjlemmafile:\n",
    "    conj_lemmas_raw = conjlemmafile.readlines()\n",
    "\n",
    "print(\"Metric #2: Vocab (lemmas) scores\")\n",
    "conj_lemma_scores = {}\n",
    "for conjecture in conj_lemmas_raw:\n",
    "    conj_lemma_scores[conjecture] = 0\n",
    "    conj_lemmas = conjecture.split()\n",
    "    num = 0\n",
    "    for lemma in conj_lemmas:\n",
    "        if lemma not in stopwords_raw:\n",
    "            num += 1\n",
    "            if lemma in lemma_dict:\n",
    "                conj_lemma_scores[conjecture] += lemma_dict[lemma]\n",
    "    if num == 0:\n",
    "        num = 1\n",
    "    conj_lemma_scores[conjecture] = conj_lemma_scores[conjecture] / (lemma_norm * num)\n",
    "    print(conjecture.strip(), conj_lemma_scores[conjecture])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric #3: Syntax/style (bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric #3: Syntax/style (bigrams) scores\n",
      "ὅς γ’ οὐ λογίζῃ, πῶς δε πιστεύοιμι σοι; 0.0878\n",
      "ὥς στέρεος εῖ! τί οὐχὶ πιστεύεις ἐμοί; 0.0786\n",
      "θέλεις λέγειν με δεῖν πιθέσθαι σοι, Κρέων; 0.0091\n",
      "τί ποτε πιθοίμην ἂν γε τοῖςδε σοῖς λόγοις; 0.3583\n",
      "μηδείς δε πιστεύσει γέ σοι, ὀρθῶς φρονῶν. 0.0018\n"
     ]
    }
   ],
   "source": [
    "print(\"Metric #3: Syntax/style (bigrams) scores\")\n",
    "\n",
    "bigrams_conjectures = []\n",
    "conj_bigram_scores = {}\n",
    "for conjecture in conjectures:\n",
    "    words = conjecture.split()\n",
    "    stripped_words = []\n",
    "    for word in words:\n",
    "        stripped_word = word.strip(',;.ʼ·:!')\n",
    "        stripped_words.append(stripped_word)\n",
    "    stripped_words.insert(0, 'start')\n",
    "    stripped_words.append('end')\n",
    "    bigrams = list(nltk.bigrams(stripped_words))\n",
    "\n",
    "    conj_bigram_scores[conjecture] = 0\n",
    "    for bigram in bigrams:\n",
    "        if bigram in bigram_dict:\n",
    "            conj_bigram_scores[conjecture] += bigram_dict[bigram]\n",
    "    conj_bigram_scores[conjecture] = round((conj_bigram_scores[conjecture] - bigram_min) / (bigram_max - bigram_min), 4)\n",
    "    print(conjecture.strip(), conj_bigram_scores[conjecture])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric #4: Amount of information (stop words, support words, and significant words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric #4: Amount of information (stop words, support words, and significant words) scores\n",
      "ὅς γ’ οὐ λογίζῃ, πῶς δε πιστεύοιμι σοι; 0.625\n",
      "ὥς στέρεος εῖ! τί οὐχὶ πιστεύεις ἐμοί; 0.375\n",
      "θέλεις λέγειν με δεῖν πιθέσθαι σοι, Κρέων; 0.75\n",
      "τί ποτε πιθοίμην ἂν γε τοῖςδε σοῖς λόγοις; 0.5625\n",
      "μηδείς δε πιστεύσει γέ σοι, ὀρθῶς φρονῶν. 0.625\n"
     ]
    }
   ],
   "source": [
    "print(\"Metric #4: Amount of information (stop words, support words, and significant words) scores\")\n",
    "conj_signif_scores = {}\n",
    "for conjecture in conjectures:\n",
    "    conj_signif_scores[conjecture] = 0\n",
    "    words = conjecture.split()\n",
    "    bare_words = []\n",
    "    for word in words:\n",
    "        bare_word = \"\"\n",
    "        stripped_word = word.strip(',;.ʼ·:!')\n",
    "        for letter in stripped_word:\n",
    "            if letter in 'ἈἉἊἋἌἍἎἏᾺἀἁἂἃἄἅἆἇὰᾶάᾼᾈᾉᾊᾋᾌᾍᾎᾏᾳᾀᾁᾂᾃᾄᾅᾆᾇᾲᾷ':\n",
    "                bare_word = bare_word + 'α'\n",
    "            elif letter in 'ἘἙἚἛἜἝῈἐἑἒἓἔἕὲέ':\n",
    "                bare_word = bare_word + 'ε'\n",
    "            elif letter in 'ἨἩἪἫἬἭἮἯῊἠἡἢἣἤἥἦἧὴῆήῌᾘᾙᾚᾛᾝᾞᾟῃᾐᾑᾒᾓᾔᾕᾖᾗῂῇῄ':\n",
    "                bare_word = bare_word + 'η'\n",
    "            elif letter in 'ἸἹἺἻἼἽἾἿῚἰἱἲἳἴἵἶἷὶῖί':\n",
    "                bare_word = bare_word + 'ι'\n",
    "            elif letter in 'ὈὉὊὋὌὍῸὀὁὂὃὄὅὸό':\n",
    "                bare_word = bare_word + 'ο'\n",
    "            elif letter in 'ὙὛὝὟῪὐὑὒὓὔὕὖὗὺῦῧῢΰύ':\n",
    "                bare_word = bare_word + 'υ'\n",
    "            elif letter in 'ὨὩὪὫὬὭὮὯῺὠὡὢὣὤὥὦὧὼῶώῼᾨᾩᾪᾫᾬᾭᾮᾯῳᾠᾡᾢᾣᾤᾥᾦᾧῲῷῴ':\n",
    "                bare_word = bare_word + 'ω'\n",
    "            else:\n",
    "                bare_word = bare_word + letter\n",
    "        bare_words.append(bare_word)\n",
    "    for bare_word in bare_words:\n",
    "        if bare_word in stopwords:\n",
    "            conj_signif_scores[conjecture] += 1\n",
    "        elif bare_word in midwords:\n",
    "            conj_signif_scores[conjecture] += 2\n",
    "        else:\n",
    "            conj_signif_scores[conjecture] += 3\n",
    "    conj_signif_scores[conjecture] = round((conj_signif_scores[conjecture] - signif_min) / (signif_max - signif_min), 4)\n",
    "    print(conjecture.strip(), conj_signif_scores[conjecture])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
